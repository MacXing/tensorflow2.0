{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 3.1.1\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "tensorflow 2.0.0-alpha0\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import sklearn\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "#答应版本\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "(x_train_all,y_train_all),(x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_valid,x_train = x_train_all[:5000],x_train_all[5000:]\n",
    "y_valid,y_train = y_train_all[:5000],y_train_all[5000:]\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "x_valid_scaler = scaler.fit_transform(\n",
    "    x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "x_test_scaler = scaler.fit_transform(\n",
    "    x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0231433 -0.8105136\n"
     ]
    }
   ],
   "source": [
    "print(np.max(x_train_scaled),np.min(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.Sequential()\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation='relu'))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28,28]),\n",
    "#     model.add(keras.layers.Dense(300,activation='relu')),\n",
    "#     model.add(keras.layers.Dense(100,activation='relu')),\n",
    "#     model.add(keras.layers.Dense(10,activation='softmax')),\n",
    "# ])\n",
    "\n",
    "#relu : y  = max(0,x)\n",
    "#softmax: 将向量变成概率分布 x = [x1,x2,x3] y = [e^x1/sum,e^x2/sum,e^x3/sum] sum = e^x1+e^x2+e^x\n",
    "\n",
    "#loss 如果lable 是一个one-hot 向量 ：categorical_croossentropy，不是向量：sparse_categorical_crossentropy\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.9153 - accuracy: 0.7068 - val_loss: 0.6241 - val_accuracy: 0.7940\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.5796 - accuracy: 0.8021 - val_loss: 0.5271 - val_accuracy: 0.8208\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.5125 - accuracy: 0.8226 - val_loss: 0.4858 - val_accuracy: 0.8340\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4769 - accuracy: 0.8323 - val_loss: 0.4597 - val_accuracy: 0.8450\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.4530 - accuracy: 0.8404 - val_loss: 0.4452 - val_accuracy: 0.8472\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.4355 - accuracy: 0.8453 - val_loss: 0.4299 - val_accuracy: 0.8544\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.4217 - accuracy: 0.8505 - val_loss: 0.4184 - val_accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.4101 - accuracy: 0.8538 - val_loss: 0.4121 - val_accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.4003 - accuracy: 0.8569 - val_loss: 0.4050 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3923 - accuracy: 0.8602 - val_loss: 0.3982 - val_accuracy: 0.8636\n"
     ]
    }
   ],
   "source": [
    "logdir = r'C:\\Users\\Xiaoi\\Desktop\\tensorflow2.0\\callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"fashion_mnist_model.h5\")\n",
    "\n",
    "_callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),#tensotBoard 路径\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                   save_best_only=True), #保存最好的模型\n",
    "    keras.callbacks.EarlyStopping(patience=5,\n",
    "                                 min_delta=1e-3) # 5轮之内，最低为1e-3 就停止\n",
    "]\n",
    "history = model.fit(x_train_scaled,\n",
    "                    y_train,\n",
    "                   epochs=10,\n",
    "                   validation_data=(x_valid_scaler,y_valid),\n",
    "                   callbacks=_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
